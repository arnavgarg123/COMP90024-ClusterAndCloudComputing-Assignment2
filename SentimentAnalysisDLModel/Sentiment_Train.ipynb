{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/arnav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/arnav/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"./archive/training.1600000.processed.noemoticon.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(file,encoding='ISO-8859-1',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['sentiment','id','date','query','username','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "          username                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','date','query','username'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment']=df['sentiment'].replace(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False, lemmatize=False):\n",
    "    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "    cleaned_text = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                if lemmatize:\n",
    "                    cleaned_text.append(lemmatizer.lemmatize(stemmer.stem(token)))\n",
    "                else:\n",
    "                    cleaned_text.append(stemmer.stem(token))\n",
    "            elif lemmatize:\n",
    "                    cleaned_text.append(lemmatizer.lemmatize(stemmer.stem(token)))\n",
    "            else:\n",
    "                cleaned_text.append(token)\n",
    "    return \" \".join(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: preprocess(x,stem=False,lemmatize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               awww bummer shoulda got david carr third day\n",
       "1          upset update facebook texting might cry result...\n",
       "2          dived many times ball managed save 50 rest go ...\n",
       "3                           whole body feels itchy like fire\n",
       "4                                           behaving mad see\n",
       "                                 ...                        \n",
       "1599995                        woke school best feeling ever\n",
       "1599996             thewdb com cool hear old walt interviews\n",
       "1599997                      ready mojo makeover ask details\n",
       "1599998    happy 38th birthday boo alll time tupac amaru ...\n",
       "1599999    happy charitytuesday thenspcc sparkscharity sp...\n",
       "Name: text, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data size: 1280000\n",
      "Test Data size 320000\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, train_size=0.8,\n",
    "                                         random_state=7,) # Splits Dataset into Training and Testing set\n",
    "print(\"Train Data size:\", len(train_data))\n",
    "print(\"Test Data size\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size : 290576\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=True,)\n",
    "tokenizer.fit_on_texts(train_data['text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size :\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "#with open('tokenizer.pickle', 'rb') as handle:\n",
    "#    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X Shape: (1280000, 30)\n",
      "Testing X Shape: (320000, 30)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(train_data['text'],),\n",
    "                        maxlen = MAX_SEQUENCE_LENGTH)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(test_data['text']),\n",
    "                       maxlen = MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(\"Training X Shape:\",x_train.shape)\n",
    "print(\"Testing X Shape:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_data['sentiment']\n",
    "y_test=test_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open('/home/arnav/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = value = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' %len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit: 91398 \n",
      "miss: 199177\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "hit=0\n",
    "miss=0\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        hit+=1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        miss+=1\n",
    "print(\"hit:\",hit,\"\\nmiss:\",miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size,\n",
    "                                          300,\n",
    "                                          weights=[embedding_matrix],\n",
    "                                          input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                          trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential()\n",
    "model.add(Input(shape=(MAX_SEQUENCE_LENGTH)))\n",
    "model.add(Embedding(vocab_size, 50, name=\"embedding\"))\n",
    "#model.add(embedding_layer)\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "#model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, monitor = 'val_loss', verbose = 1)\n",
    "valLoss=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3)\n",
    "save=tf.keras.callbacks.ModelCheckpoint('./model/model_{val_accuracy:.3f}.h5',save_best_only=True,save_weights_only=False,monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.5506 - accuracy: 0.7033 - val_loss: 0.4722 - val_accuracy: 0.7754 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.4646 - accuracy: 0.7803 - val_loss: 0.4614 - val_accuracy: 0.7819 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4578 - val_accuracy: 0.7842 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 93s 149ms/step - loss: 0.4340 - accuracy: 0.7997 - val_loss: 0.4574 - val_accuracy: 0.7856 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 93s 150ms/step - loss: 0.4230 - accuracy: 0.8060 - val_loss: 0.4577 - val_accuracy: 0.7856 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 192s 308ms/step - loss: 0.4132 - accuracy: 0.8117 - val_loss: 0.4583 - val_accuracy: 0.7856 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 197s 316ms/step - loss: 0.4040 - accuracy: 0.8167 - val_loss: 0.4617 - val_accuracy: 0.7849 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=2048, epochs=10,\n",
    "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau,valLoss,save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(\"./model/model_0.786.h5\")\n",
    "model.save(\"my_h5_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model1=tf.keras.models.Sequential()\n",
    "model1.add(Input(shape=(MAX_SEQUENCE_LENGTH)))\n",
    "model1.add(Embedding(vocab_size, 50, name=\"embedding\"))\n",
    "#model1.add(embedding_layer)\n",
    "model1.add(SpatialDropout1D(0.2))\n",
    "model1.add(Conv1D(64, 5, activation='relu'))\n",
    "model1.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model1.add(Dense(512,activation='relu'))\n",
    "#model1.add(Dropout(0.5))\n",
    "#model1.add(Dense(512,activation='relu'))\n",
    "#model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model1.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, monitor = 'val_loss', verbose = 1)\n",
    "valLoss=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3)\n",
    "save=tf.keras.callbacks.ModelCheckpoint('./model_new_embed/model_{val_accuracy:.3f}.h5',save_best_only=True,save_weights_only=False,monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 86s 137ms/step - loss: 0.5477 - accuracy: 0.7089 - val_loss: 0.4725 - val_accuracy: 0.7749 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.4645 - accuracy: 0.7803 - val_loss: 0.4610 - val_accuracy: 0.7819 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.4463 - accuracy: 0.7921 - val_loss: 0.4594 - val_accuracy: 0.7842 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.4333 - accuracy: 0.8006 - val_loss: 0.4576 - val_accuracy: 0.7852 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 91s 145ms/step - loss: 0.4214 - accuracy: 0.8074 - val_loss: 0.4574 - val_accuracy: 0.7859 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 92s 148ms/step - loss: 0.4107 - accuracy: 0.8134 - val_loss: 0.4597 - val_accuracy: 0.7855 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.4010 - accuracy: 0.8187 - val_loss: 0.4627 - val_accuracy: 0.7848 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 89s 142ms/step - loss: 0.3915 - accuracy: 0.8238 - val_loss: 0.4664 - val_accuracy: 0.7837 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(x_train, y_train, batch_size=2048, epochs=10,\n",
    "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau,valLoss,save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model1=tf.keras.models.load_model(\"./model_new_embed/model_0.786.h5\")\n",
    "model1.save(\"my_h5_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 80s 8ms/step - loss: 0.4574 - accuracy: 0.7859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45744165778160095, 0.7859343886375427]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model2=tf.keras.models.Sequential()\n",
    "model2.add(Input(shape=(MAX_SEQUENCE_LENGTH)))\n",
    "model2.add(Embedding(vocab_size, 50, name=\"embedding\"))\n",
    "#model2.add(embedding_layer)\n",
    "model2.add(SpatialDropout1D(0.2))\n",
    "model2.add(Conv1D(64, 5, activation='elu'))\n",
    "model2.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model2.add(Dense(512,activation='elu'))\n",
    "#model2.add(Dropout(0.5))\n",
    "#model2.add(Dense(512,activation='relu'))\n",
    "#model2.add(Dense(1,activation='sigmoid'))\n",
    "model2.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'],)\n",
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, monitor = 'val_loss', verbose = 1)\n",
    "valLoss=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3)\n",
    "save=tf.keras.callbacks.ModelCheckpoint('./model_new_embed_elu/model_{val_accuracy:.3f}.h5',save_best_only=True,save_weights_only=False,monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 89s 142ms/step - loss: 0.5444 - accuracy: 0.7132 - val_loss: 0.4752 - val_accuracy: 0.7751 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.4665 - accuracy: 0.7797 - val_loss: 0.4618 - val_accuracy: 0.7819 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 91s 145ms/step - loss: 0.4485 - accuracy: 0.7908 - val_loss: 0.4587 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 89s 142ms/step - loss: 0.4360 - accuracy: 0.7982 - val_loss: 0.4583 - val_accuracy: 0.7836 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.4253 - accuracy: 0.8046 - val_loss: 0.4585 - val_accuracy: 0.7837 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.4156 - accuracy: 0.8098 - val_loss: 0.4617 - val_accuracy: 0.7829 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.4060 - accuracy: 0.8141 - val_loss: 0.4638 - val_accuracy: 0.7819 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(x_train, y_train, batch_size=2048, epochs=10,\n",
    "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau,valLoss,save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model2=tf.keras.models.load_model(\"./model_new_embed_elu/model_0.784.h5\")\n",
    "model2.save(\"my_h5_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "modelelu=tf.keras.models.load_model(\"my_h5_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle=open('tokenizer.pickle', 'rb')\n",
    "tokenizer1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/arnav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_test = stopwords.words('english')\n",
    "text_cleaning_re_test = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text=\"This is a nice car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(text):\n",
    "    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "    cleaned_text = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words_test:\n",
    "                cleaned_text.append(token)\n",
    "    return \" \".join(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test=preprocess_test(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nice car'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test=tf.keras.preprocessing.sequence.pad_sequences(tokenizer1.texts_to_sequences([text_test],),\n",
    "                        maxlen = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  61, 209]], dtype=int32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2666841 , 0.73331594]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelelu.predict(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
